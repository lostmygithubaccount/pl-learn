{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST \n",
    "\n",
    "MNIST stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "from Azure? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "container_name = \"datasets\"\n",
    "storage_options = {\"account_name\": \"azuremlexamples\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<adlfs.spec.AzureBlobFileSystem at 0x7f7eb037a820>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = AzureBlobFileSystem(**storage_options)\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['datasets/mnist/t10k-images-idx3-ubyte.gz',\n 'datasets/mnist/t10k-labels-idx1-ubyte.gz',\n 'datasets/mnist/train-images-idx3-ubyte.gz',\n 'datasets/mnist/train-labels-idx1-ubyte.gz']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = fs.ls(f\"{container_name}/mnist\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a LightningDataModule \n",
    "\n",
    "This is tricky! Not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from adlfs import AzureBlobFileSystem\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class AzureMLMNISTDataModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, batch_size: int=10):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        data_dir = \"datasets/mnist\"        \n",
    "        storage_options = {\"account_name\": \"azuremlexamples\"}\n",
    "        fs = AzureBlobFileSystem(**storage_options)\n",
    "        files = fs.ls(data_dir)\n",
    "\n",
    "        train_len = 60000\n",
    "        test_len = 10000\n",
    "        \n",
    "        for f in files:\n",
    "            if \"train-images\" in f:\n",
    "                self.X_train = self._read_images(gzip.open(fs.open(f)), train_len)\n",
    "            elif \"train-labels\" in f:\n",
    "                self.y_train = self._read_labels(gzip.open(fs.open(f)), train_len)\n",
    "            elif \"images\" in f:\n",
    "                self.X_test = self._read_images(gzip.open(fs.open(f)), test_len)\n",
    "            elif \"labels\" in f:\n",
    "                self.y_test = self._read_labels(gzip.open(fs.open(f)), test_len)\n",
    "\n",
    "        self.ohe = OneHotEncoder().fit(self.y_train.reshape(-1, 1))\n",
    "\n",
    "        self.mnist_train = list(zip(self.X_train, self.ohe.transform(self.y_train.reshape(-1, 1)).toarray()))\n",
    "        self.mnist_test = list(zip(self.X_test, self.ohe.transform(self.y_test.reshape(-1, 1)).toarray()))\n",
    "\n",
    "    def _read_images(self, f, images):\n",
    "        image_size = 28\n",
    "        \n",
    "        f.read(16) # magic\n",
    "        buf = f.read(image_size * image_size * images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(images, image_size, image_size, 1)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _read_labels(self, f, labels):\n",
    "\n",
    "        f.read(8) # magic\n",
    "\n",
    "        buf = f.read(1 * labels)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        return labels\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = AzureMLMNISTDataModule()\n",
    "mnist.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for batch in mnist.mnist_test:\n",
    "    x, y = batch\n",
    "\n",
    "    plt.imshow(x.squeeze())\n",
    "    print(f\"Label: {y}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun Time!\n",
    "\n",
    "the work pays off?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "\n",
    "class System1(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "        # magic\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "                        nn.Linear(28 * 28, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, 256),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(256, 10),\n",
    "                        nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(self.batch_size, -1)\n",
    "        y = y.view(self.batch_size, -1)\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.binary_cross_entropy(y_hat, y.float())\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "System1(\n  (net): Sequential(\n    (0): Linear(in_features=784, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=10, bias=True)\n    (5): Softmax(dim=None)\n  )\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system1 = System1(mnist.batch_size)\n",
    "system1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 136 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  24%|██▍       | 14589/60000 [01:08<03:33, 212.45it/s, loss=17, v_num=8]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(system1, mnist.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST \n",
    "\n",
    "test = MNIST(\".\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}